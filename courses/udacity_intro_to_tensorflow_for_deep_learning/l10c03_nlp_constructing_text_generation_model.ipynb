{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlanTinajero/Computervisionmodel/blob/main/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50009e5-c73b-43c7-c1fd-dee2da2f0957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-03 02:15:16--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.115.102, 172.253.115.100, 172.253.115.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.115.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uh67r4345itpvbe2cdvo2nahb2tv7lpo/1680488100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=134a768a-6915-45e2-96d6-07189c3dbe47 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-03 02:15:18--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uh67r4345itpvbe2cdvo2nahb2tv7lpo/1680488100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=134a768a-6915-45e2-96d6-07189c3dbe47\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 142.251.167.132, 2607:f8b0:4004:c1d::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|142.251.167.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   133MB/s    in 0.5s    \n",
            "\n",
            "2023-04-03 02:15:19 (133 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "apcEXp7WhVBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1c5a4b-041e-4c00-ded4-7bb720cceb1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-fbdddccf8583>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-fbdddccf8583>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.lower()\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zsmu3aEId49i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec9434c-2799-4514-b37a-f315154586f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G1YXuxIqfygN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ce8efd-6d19-4a90-a0b1-67537fa60104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 15s 94ms/step - loss: 5.9733 - accuracy: 0.0303\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 5.4351 - accuracy: 0.0303\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 5.3655 - accuracy: 0.0348\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 5.3012 - accuracy: 0.0348\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.2205 - accuracy: 0.0404\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.1216 - accuracy: 0.0434\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 5.0295 - accuracy: 0.0474\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 4.9379 - accuracy: 0.0510\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 4.8570 - accuracy: 0.0616\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7657 - accuracy: 0.0676\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.6787 - accuracy: 0.0732\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6057 - accuracy: 0.0777\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5341 - accuracy: 0.0767\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4615 - accuracy: 0.0918\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4125 - accuracy: 0.1115\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.3263 - accuracy: 0.1211\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.2625 - accuracy: 0.1352\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1970 - accuracy: 0.1408\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.1563 - accuracy: 0.1448\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0919 - accuracy: 0.1549\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0217 - accuracy: 0.1630\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9623 - accuracy: 0.1756\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9012 - accuracy: 0.1771\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.8449 - accuracy: 0.1857\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7981 - accuracy: 0.1932\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7417 - accuracy: 0.1927\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.6864 - accuracy: 0.2129\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.6314 - accuracy: 0.2281\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5860 - accuracy: 0.2366\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5480 - accuracy: 0.2432\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.5103 - accuracy: 0.2573\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.4446 - accuracy: 0.2684\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.4033 - accuracy: 0.2800\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.3571 - accuracy: 0.2765\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2978 - accuracy: 0.2901\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2388 - accuracy: 0.3063\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.2152 - accuracy: 0.3047\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1702 - accuracy: 0.3169\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1044 - accuracy: 0.3421\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0738 - accuracy: 0.3411\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0199 - accuracy: 0.3582\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9636 - accuracy: 0.3713\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9369 - accuracy: 0.3784\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8945 - accuracy: 0.3935\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.8478 - accuracy: 0.4062\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8163 - accuracy: 0.4041\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.7560 - accuracy: 0.4243\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6996 - accuracy: 0.4354\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6588 - accuracy: 0.4485\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6236 - accuracy: 0.4465\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5832 - accuracy: 0.4460\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5422 - accuracy: 0.4662\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4948 - accuracy: 0.4778\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4743 - accuracy: 0.4889\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4135 - accuracy: 0.5015\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 2.3799 - accuracy: 0.5106\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3886 - accuracy: 0.5126\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3336 - accuracy: 0.5146\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.2844 - accuracy: 0.5338\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.2471 - accuracy: 0.5444\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2125 - accuracy: 0.5499\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1676 - accuracy: 0.5585\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1422 - accuracy: 0.5580\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1072 - accuracy: 0.5686\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0720 - accuracy: 0.5732\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0406 - accuracy: 0.5827\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0269 - accuracy: 0.5807\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0283 - accuracy: 0.5777\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9680 - accuracy: 0.5938\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9239 - accuracy: 0.6054\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8891 - accuracy: 0.6115\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8639 - accuracy: 0.6155\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8295 - accuracy: 0.6165\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8000 - accuracy: 0.6241\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7884 - accuracy: 0.6266\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7806 - accuracy: 0.6206\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7321 - accuracy: 0.6297\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7236 - accuracy: 0.6342\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6826 - accuracy: 0.6398\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6529 - accuracy: 0.6488\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6198 - accuracy: 0.6650\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5998 - accuracy: 0.6584\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5728 - accuracy: 0.6771\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5615 - accuracy: 0.6670\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5428 - accuracy: 0.6756\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5035 - accuracy: 0.6837\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4807 - accuracy: 0.6857\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4660 - accuracy: 0.6922\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4410 - accuracy: 0.6963\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4120 - accuracy: 0.7064\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4058 - accuracy: 0.7069\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.3729 - accuracy: 0.7084\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3533 - accuracy: 0.7175\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3385 - accuracy: 0.7124\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3259 - accuracy: 0.7124\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3152 - accuracy: 0.7159\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2956 - accuracy: 0.7149\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2794 - accuracy: 0.7180\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3455 - accuracy: 0.7043\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2943 - accuracy: 0.7089\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.2521 - accuracy: 0.7260\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2326 - accuracy: 0.7275\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2130 - accuracy: 0.7321\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1952 - accuracy: 0.7422\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2031 - accuracy: 0.7331\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3646 - accuracy: 0.6862\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2429 - accuracy: 0.7200\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1918 - accuracy: 0.7402\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1553 - accuracy: 0.7361\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.1475 - accuracy: 0.7427\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1253 - accuracy: 0.7503\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.1055 - accuracy: 0.7608\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0695 - accuracy: 0.7679\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0548 - accuracy: 0.7750\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0387 - accuracy: 0.7765\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0278 - accuracy: 0.7805\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0135 - accuracy: 0.7846\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0042 - accuracy: 0.7825\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9886 - accuracy: 0.7876\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9763 - accuracy: 0.7886\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9623 - accuracy: 0.7926\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9522 - accuracy: 0.7931\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9459 - accuracy: 0.7936\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9367 - accuracy: 0.7957\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9240 - accuracy: 0.7926\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9194 - accuracy: 0.7967\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9027 - accuracy: 0.8022\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8965 - accuracy: 0.8012\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9024 - accuracy: 0.8027\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9031 - accuracy: 0.7977\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9028 - accuracy: 0.7962\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8826 - accuracy: 0.8042\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8583 - accuracy: 0.8108\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8427 - accuracy: 0.8123\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8310 - accuracy: 0.8138\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8168 - accuracy: 0.8194\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8103 - accuracy: 0.8194\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8030 - accuracy: 0.8209\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8037 - accuracy: 0.8244\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7932 - accuracy: 0.8234\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8117 - accuracy: 0.8174\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7929 - accuracy: 0.8214\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7755 - accuracy: 0.8290\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7712 - accuracy: 0.8259\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8187 - accuracy: 0.8143\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7709 - accuracy: 0.8259\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7395 - accuracy: 0.8355\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7262 - accuracy: 0.8345\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7166 - accuracy: 0.8411\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7076 - accuracy: 0.8426\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7038 - accuracy: 0.8441\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.8416\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6864 - accuracy: 0.8426\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.8486\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6719 - accuracy: 0.8512\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.8360\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6827 - accuracy: 0.8456\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.8496\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6700 - accuracy: 0.8446\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6525 - accuracy: 0.8461\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6400 - accuracy: 0.8512\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6319 - accuracy: 0.8542\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6416 - accuracy: 0.8507\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6229 - accuracy: 0.8552\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6168 - accuracy: 0.8552\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6340 - accuracy: 0.8527\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6647 - accuracy: 0.8391\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6727 - accuracy: 0.8426\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6986 - accuracy: 0.8330\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.8451\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.8391\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6570 - accuracy: 0.8496\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6583 - accuracy: 0.8411\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6353 - accuracy: 0.8441\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6018 - accuracy: 0.8542\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.8547\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.8618\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5636 - accuracy: 0.8643\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5582 - accuracy: 0.8628\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5503 - accuracy: 0.8653\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.8708\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.8693\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.8683\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.8713\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.8703\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.8698\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.8693\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5133 - accuracy: 0.8744\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5070 - accuracy: 0.8713\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5113 - accuracy: 0.8703\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5149 - accuracy: 0.8698\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5156 - accuracy: 0.8693\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.8628\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5002 - accuracy: 0.8688\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.8708\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4820 - accuracy: 0.8729\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.8789\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.8769\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.8814\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.8779\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aeSNfS7uhch0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e6ad24c3-5f50-41a3-8e1e-21d9517475b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DC7zfcgviDTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e53c7ce-ae30-4308-ed59-99c759538e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 650ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "im feeling chills me to do it as good as new was for you hearts with the fate evening front evening evening front velvet new do new life life life life life life life life life life life life life life cassandra me am think weave eyes truth truth kind life life life life life think life life life life life think life life life life life life have life have life life life life have life have life life life me life me life life have here have did life life life life have life life life life life life life cassandra\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c03_nlp_constructing_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}